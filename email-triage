#!/Users/laurent/.local/bin/uv run --script
# /// script
# requires-python = ">=3.11"
# dependencies = [
#     "google-auth>=2.0",
#     "google-auth-oauthlib>=1.0",
#     "google-api-python-client>=2.0",
#     "requests>=2.31",
# ]
# ///
"""
Email Triage Helper - Gmail + Todoist + SQLite for Hammerspoon
"""

import argparse
import json
import os
import sqlite3
import subprocess
import sys
from datetime import datetime
from pathlib import Path
from typing import Optional

# Gmail API imports
from google.oauth2.credentials import Credentials
from google.auth.transport.requests import Request
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError

# --- Configuration ---
DB_PATH = Path.home() / ".email-triage.db"
TOKEN_CACHE = Path.home() / ".config" / "email-triage" / "token.json"
CREDENTIALS_FILE = Path.home() / ".config" / "email-triage" / "credentials.json"

# Gmail OAuth scopes
SCOPES = [
    "https://www.googleapis.com/auth/gmail.modify",
    "https://www.googleapis.com/auth/gmail.labels",
]


# --- SQLite Decision Logger ---
class DecisionDB:
    def __init__(self, db_path: Path = DB_PATH):
        self.db_path = db_path
        self.conn = sqlite3.connect(str(db_path))
        self._create_tables()

    def _create_tables(self):
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS decisions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                message_id TEXT NOT NULL,
                thread_id TEXT,
                subject TEXT,
                from_addr TEXT,
                snippet TEXT,
                action TEXT CHECK(action IN ('archive', 'task', 'delete', 'suppress')),
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        """)
        self.conn.execute("CREATE INDEX IF NOT EXISTS idx_message_id ON decisions(message_id)")
        self.conn.execute("CREATE INDEX IF NOT EXISTS idx_action ON decisions(action)")
        self.conn.execute("CREATE INDEX IF NOT EXISTS idx_timestamp ON decisions(timestamp)")

        # Pending actions for offline mode
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS pending_actions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                message_id TEXT NOT NULL,
                thread_id TEXT,
                subject TEXT,
                from_addr TEXT,
                snippet TEXT,
                action TEXT CHECK(action IN ('archive', 'task', 'delete', 'suppress')),
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        """)
        self.conn.commit()

    def log(self, message_id: str, thread_id: str, subject: str, from_addr: str,
            snippet: str, action: str):
        self.conn.execute(
            """INSERT INTO decisions (message_id, thread_id, subject, from_addr, snippet, action)
               VALUES (?, ?, ?, ?, ?, ?)""",
            (message_id, thread_id, subject, from_addr, snippet, action)
        )
        self.conn.commit()

    def get_stats(self) -> dict:
        cursor = self.conn.execute("""
            SELECT action, COUNT(*) as count
            FROM decisions
            GROUP BY action
        """)
        stats = {row[0]: row[1] for row in cursor.fetchall()}

        cursor = self.conn.execute("SELECT COUNT(*) FROM decisions")
        stats["total"] = cursor.fetchone()[0]

        cursor = self.conn.execute("SELECT COUNT(*) FROM pending_actions")
        stats["pending"] = cursor.fetchone()[0]

        return stats

    def queue_action(self, message_id: str, thread_id: str, subject: str,
                     from_addr: str, snippet: str, action: str):
        """Queue an action for offline sync."""
        self.conn.execute(
            """INSERT INTO pending_actions (message_id, thread_id, subject, from_addr, snippet, action)
               VALUES (?, ?, ?, ?, ?, ?)""",
            (message_id, thread_id, subject, from_addr, snippet, action)
        )
        self.conn.commit()

    def get_pending(self) -> list[dict]:
        """Get all pending actions."""
        cursor = self.conn.execute(
            """SELECT id, message_id, thread_id, subject, from_addr, snippet, action, created_at
               FROM pending_actions ORDER BY created_at"""
        )
        return [
            {"id": row[0], "message_id": row[1], "thread_id": row[2],
             "subject": row[3], "from_addr": row[4], "snippet": row[5],
             "action": row[6], "created_at": row[7]}
            for row in cursor.fetchall()
        ]

    def remove_pending(self, pending_id: int):
        """Remove a pending action after successful sync."""
        self.conn.execute("DELETE FROM pending_actions WHERE id = ?", (pending_id,))
        self.conn.commit()

    def close(self):
        self.conn.close()


# --- Todoist Client ---
class TodoistClient:
    def __init__(self):
        self.token = self._get_token_from_keychain()
        self.base_url = "https://api.todoist.com/rest/v2"
        self.headers = {"Authorization": f"Bearer {self.token}"}

    def _get_token_from_keychain(self) -> str:
        try:
            result = subprocess.check_output(
                ["security", "find-generic-password", "-s", "org-todoist", "-w"],
                stderr=subprocess.DEVNULL
            )
            return result.decode().strip()
        except subprocess.CalledProcessError:
            raise RuntimeError("Todoist token not found in keychain. Add with: security add-generic-password -s org-todoist -a todoist -w 'YOUR_TOKEN'")

    def create_task(self, content: str, description: str = None,
                    project_name: str = None, labels: list = None) -> dict:
        import requests

        data = {"content": content}
        if description:
            data["description"] = description
        if labels:
            data["labels"] = labels

        response = requests.post(
            f"{self.base_url}/tasks",
            headers=self.headers,
            json=data,
            timeout=10
        )
        response.raise_for_status()
        return response.json()


# --- Gmail Client ---
class GmailClient:
    def __init__(self):
        self.creds = self._get_credentials()
        self.service = build("gmail", "v1", credentials=self.creds)

    def _get_credentials(self) -> Credentials:
        creds = None

        # Load cached token
        if TOKEN_CACHE.exists():
            with open(TOKEN_CACHE, "r") as f:
                token_data = json.load(f)
            creds = Credentials(
                token=token_data.get("token"),
                refresh_token=token_data.get("refresh_token"),
                token_uri=token_data.get("token_uri"),
                client_id=token_data.get("client_id"),
                client_secret=token_data.get("client_secret"),
                scopes=SCOPES
            )

        # Refresh if expired
        if creds and creds.expired and creds.refresh_token:
            creds.refresh(Request())
            self._save_token(creds)

        if not creds or not creds.valid:
            raise RuntimeError(
                f"Gmail not authenticated. Run: email-triage setup\n"
                f"Token cache: {TOKEN_CACHE}"
            )

        return creds

    def _save_token(self, creds: Credentials):
        TOKEN_CACHE.parent.mkdir(parents=True, exist_ok=True)
        token_data = {
            "token": creds.token,
            "refresh_token": creds.refresh_token,
            "token_uri": creds.token_uri,
            "client_id": creds.client_id,
            "client_secret": creds.client_secret,
        }
        with open(TOKEN_CACHE, "w") as f:
            json.dump(token_data, f)
        os.chmod(TOKEN_CACHE, 0o600)  # Secure permissions

    def _strip_html(self, html: str) -> str:
        """Strip HTML tags and decode entities to get readable text."""
        import re
        import html as html_module

        # Remove style, script, and head blocks entirely
        text = re.sub(r'<head[^>]*>.*?</head>', '', html, flags=re.DOTALL | re.IGNORECASE)
        text = re.sub(r'<style[^>]*>.*?</style>', '', text, flags=re.DOTALL | re.IGNORECASE)
        text = re.sub(r'<script[^>]*>.*?</script>', '', text, flags=re.DOTALL | re.IGNORECASE)

        # Replace common block elements with newlines
        text = re.sub(r'<br\s*/?>', '\n', text, flags=re.IGNORECASE)
        text = re.sub(r'</(p|div|tr|li|h[1-6])>', '\n', text, flags=re.IGNORECASE)

        # Remove all remaining tags
        text = re.sub(r'<[^>]+>', '', text)

        # Decode HTML entities
        text = html_module.unescape(text)

        # Remove CSS-like lines (contain { } or start with . or #)
        lines = text.split('\n')
        lines = [l for l in lines if not re.match(r'^\s*[.#@]?\w*\s*\{', l) and '{' not in l]
        text = '\n'.join(lines)

        # Clean up whitespace
        text = re.sub(r'[ \t]+', ' ', text)
        text = re.sub(r'\n\s*\n+', '\n\n', text)
        text = text.strip()

        return text

    def _extract_body(self, payload: dict, depth: int = 0) -> str:
        """Recursively extract plain text body from email payload."""
        import base64

        plain_text = None
        html_text = None

        # Direct body data
        if "body" in payload and payload["body"].get("data"):
            content = base64.urlsafe_b64decode(payload["body"]["data"]).decode("utf-8", errors="replace")
            mime_type = payload.get("mimeType", "")
            if "plain" in mime_type:
                return content
            else:
                # Strip HTML for html content or unknown types
                return self._strip_html(content)

        # Recurse into parts - prefer plain text
        if "parts" in payload:
            for part in payload["parts"]:
                mime_type = part.get("mimeType", "")
                if mime_type == "text/plain":
                    body = self._extract_body(part, depth + 1)
                    if body:
                        plain_text = body
                elif mime_type == "text/html":
                    body = self._extract_body(part, depth + 1)
                    if body:
                        html_text = body
                elif "multipart" in mime_type:
                    body = self._extract_body(part, depth + 1)
                    if body:
                        return body

            # Return plain text if found, otherwise HTML (keep for rendering)
            if plain_text:
                return plain_text
            if html_text:
                return html_text

        return ""

    def _parse_message(self, msg: dict) -> dict:
        """Parse Gmail message into simplified dict."""
        headers = {h["name"].lower(): h["value"] for h in msg["payload"].get("headers", [])}

        # Get body (recursively)
        body = self._extract_body(msg["payload"])

        # internalDate is milliseconds since epoch - use for reliable sorting
        internal_date = int(msg.get("internalDate", 0))

        return {
            "id": msg["id"],
            "threadId": msg["threadId"],
            "subject": headers.get("subject", "(no subject)"),
            "from": headers.get("from", "unknown"),
            "date": headers.get("date", ""),
            "internalDate": internal_date,  # Epoch ms for sorting
            "snippet": msg.get("snippet", ""),
            "body": body[:2000],  # Limit body size for HS performance
            "labelIds": msg.get("labelIds", []),
        }

    def fetch_inbox(self, max_results: int = 50) -> list[dict]:
        """Fetch inbox emails using batch requests with full body content."""
        import time

        try:
            # Collect message IDs with pagination
            messages = []
            page_token = None

            while len(messages) < max_results:
                results = self.service.users().messages().list(
                    userId="me",
                    labelIds=["INBOX"],
                    maxResults=min(100, max_results - len(messages)),
                    pageToken=page_token
                ).execute()

                messages.extend(results.get("messages", []))
                page_token = results.get("nextPageToken")

                if not page_token:
                    break

            if not messages:
                return []

            # Use batch requests with FULL format for body content
            # Gmail API allows up to 100 per batch
            BATCH_SIZE = 100
            BATCH_DELAY = 0.1  # Minimal delay between batches
            emails = [None] * len(messages)
            failed_indices = []

            def make_callback(index, failed_list):
                def callback(request_id, response, exception):
                    if exception is None:
                        emails[index] = self._parse_message(response)
                    else:
                        failed_list.append(index)
                return callback

            # Process in chunks of BATCH_SIZE
            for chunk_start in range(0, len(messages), BATCH_SIZE):
                chunk_end = min(chunk_start + BATCH_SIZE, len(messages))
                batch = self.service.new_batch_http_request()
                for i in range(chunk_start, chunk_end):
                    batch.add(
                        self.service.users().messages().get(
                            userId="me",
                            id=messages[i]["id"],
                            format="full"
                        ),
                        callback=make_callback(i, failed_indices)
                    )
                batch.execute()
                time.sleep(BATCH_DELAY)  # Rate limit protection

            # Retry failed requests individually with delay
            for idx in failed_indices:
                try:
                    time.sleep(0.2)
                    msg = self.service.users().messages().get(
                        userId="me",
                        id=messages[idx]["id"],
                        format="full"
                    ).execute()
                    emails[idx] = self._parse_message(msg)
                except HttpError:
                    pass  # Skip if still failing

            # Filter out any failed requests
            return [e for e in emails if e is not None]

        except HttpError as e:
            raise RuntimeError(f"Gmail API error: {e}")

    def get_email(self, message_id: str) -> dict:
        """Get single email by ID."""
        msg = self.service.users().messages().get(
            userId="me",
            id=message_id,
            format="full"
        ).execute()
        return self._parse_message(msg)

    def archive(self, message_id: str):
        """Remove INBOX and UNREAD labels (archive + mark as read)."""
        self.service.users().messages().modify(
            userId="me",
            id=message_id,
            body={"removeLabelIds": ["INBOX", "UNREAD"]}
        ).execute()

    def delete(self, message_id: str):
        """Move to trash."""
        self.service.users().messages().trash(
            userId="me",
            id=message_id
        ).execute()

    def unarchive(self, message_id: str):
        """Add INBOX label back (undo archive)."""
        self.service.users().messages().modify(
            userId="me",
            id=message_id,
            body={"addLabelIds": ["INBOX"]}
        ).execute()

    def undelete(self, message_id: str):
        """Untrash message and add back to inbox."""
        self.service.users().messages().untrash(
            userId="me",
            id=message_id
        ).execute()
        # Also add back to inbox
        self.service.users().messages().modify(
            userId="me",
            id=message_id,
            body={"addLabelIds": ["INBOX"]}
        ).execute()

    def get_total_inbox_count(self) -> int:
        """Get total number of emails in inbox (accurate count via labels API)."""
        label = self.service.users().labels().get(
            userId="me",
            id="INBOX"
        ).execute()
        return label.get("messagesTotal", 0)

    def get_labels(self) -> list[dict]:
        """Get all user labels (not system labels or IMAP artifacts)."""
        results = self.service.users().labels().list(userId="me").execute()
        labels = results.get("labels", [])

        # Labels to exclude (not actively used)
        EXCLUDED_LABELS = {
            "GUIDEPOST", "Investigation", "Kamala", "FAIRMONT",
            "GISUE", "Nicolas", "Lumi", "Aveituna",
        }

        # Filter to user labels, excluding IMAP/Gmail system folders
        user_labels = []
        for l in labels:
            if l.get("type") != "user":
                continue
            name = l.get("name", "")
            # Skip IMAP artifacts and system-looking labels
            if name.startswith("[") or name.startswith("IMAP") or "/" in name:
                continue
            # Skip excluded labels
            if name in EXCLUDED_LABELS:
                continue
            user_labels.append({"id": l["id"], "name": name})
        return sorted(user_labels, key=lambda x: x["name"].lower())

    def get_message_labels(self, message_id: str) -> list[str]:
        """Get label IDs for a message."""
        msg = self.service.users().messages().get(
            userId="me",
            id=message_id,
            format="minimal"
        ).execute()
        return msg.get("labelIds", [])

    def add_label(self, message_id: str, label_id: str):
        """Add a label to a message."""
        self.service.users().messages().modify(
            userId="me",
            id=message_id,
            body={"addLabelIds": [label_id]}
        ).execute()

    def remove_label(self, message_id: str, label_id: str):
        """Remove a label from a message."""
        self.service.users().messages().modify(
            userId="me",
            id=message_id,
            body={"removeLabelIds": [label_id]}
        ).execute()


# --- OAuth Setup ---
def setup_oauth():
    """Interactive OAuth setup."""
    from google_auth_oauthlib.flow import InstalledAppFlow

    if not CREDENTIALS_FILE.exists():
        print(f"Missing credentials file: {CREDENTIALS_FILE}")
        print("\nTo set up Gmail API:")
        print("1. Go to https://console.cloud.google.com/apis/credentials")
        print("2. Create OAuth 2.0 Client ID (Desktop app)")
        print("3. Download JSON and save to:", CREDENTIALS_FILE)
        sys.exit(1)

    CREDENTIALS_FILE.parent.mkdir(parents=True, exist_ok=True)

    flow = InstalledAppFlow.from_client_secrets_file(str(CREDENTIALS_FILE), SCOPES)
    creds = flow.run_local_server(port=0)

    # Save token
    TOKEN_CACHE.parent.mkdir(parents=True, exist_ok=True)
    token_data = {
        "token": creds.token,
        "refresh_token": creds.refresh_token,
        "token_uri": creds.token_uri,
        "client_id": creds.client_id,
        "client_secret": creds.client_secret,
    }
    with open(TOKEN_CACHE, "w") as f:
        json.dump(token_data, f)
    os.chmod(TOKEN_CACHE, 0o600)  # Secure permissions

    print(f"Token saved to: {TOKEN_CACHE}")
    print("Gmail authentication complete!")


# --- CLI Commands ---
def cmd_fetch(args):
    """Fetch inbox emails."""
    gmail = GmailClient()
    emails = gmail.fetch_inbox(max_results=args.max)
    total = gmail.get_total_inbox_count()

    result = {
        "success": True,
        "emails": emails,
        "total": total,
    }
    print(json.dumps(result))


def cmd_archive(args):
    """Archive email and log decision."""
    gmail = GmailClient()
    db = DecisionDB()

    try:
        # Get email details for logging
        email = gmail.get_email(args.message_id)

        # Archive it
        gmail.archive(args.message_id)

        # Log decision
        db.log(
            message_id=email["id"],
            thread_id=email["threadId"],
            subject=email["subject"],
            from_addr=email["from"],
            snippet=email["snippet"],
            action="archive"
        )

        print(json.dumps({"success": True, "action": "archive", "message_id": args.message_id}))
    finally:
        db.close()


def cmd_task(args):
    """Create Todoist task, then archive email."""
    gmail = GmailClient()
    todoist = TodoistClient()
    db = DecisionDB()

    try:
        # Get email details
        email = gmail.get_email(args.message_id)

        # Create Todoist task with email link
        gmail_link = f"https://mail.google.com/mail/u/0/#inbox/{email['id']}"
        task_content = f"Handle: {email['subject']}"
        task_desc = f"From: {email['from']}\n\n{gmail_link}"

        todoist.create_task(
            content=task_content,
            description=task_desc,
            labels=["email"]
        )

        # Archive email
        gmail.archive(args.message_id)

        # Log decision
        db.log(
            message_id=email["id"],
            thread_id=email["threadId"],
            subject=email["subject"],
            from_addr=email["from"],
            snippet=email["snippet"],
            action="task"
        )

        print(json.dumps({"success": True, "action": "task", "message_id": args.message_id}))
    finally:
        db.close()


def cmd_delete(args):
    """Delete email (move to trash)."""
    gmail = GmailClient()
    db = DecisionDB()

    try:
        email = gmail.get_email(args.message_id)
        gmail.delete(args.message_id)

        db.log(
            message_id=email["id"],
            thread_id=email["threadId"],
            subject=email["subject"],
            from_addr=email["from"],
            snippet=email["snippet"],
            action="delete"
        )

        print(json.dumps({"success": True, "action": "delete", "message_id": args.message_id}))
    finally:
        db.close()


def cmd_unarchive(args):
    """Unarchive email (move back to inbox)."""
    gmail = GmailClient()
    gmail.unarchive(args.message_id)
    print(json.dumps({"success": True, "action": "unarchive", "message_id": args.message_id}))


def cmd_undelete(args):
    """Undelete email (move from trash back to inbox)."""
    gmail = GmailClient()
    gmail.undelete(args.message_id)
    print(json.dumps({"success": True, "action": "undelete", "message_id": args.message_id}))


def cmd_suppress(args):
    """Create unsubscribe task, then archive email."""
    gmail = GmailClient()
    todoist = TodoistClient()
    db = DecisionDB()

    try:
        email = gmail.get_email(args.message_id)

        # Extract sender email
        from_addr = email["from"]
        # Parse "Name <email@example.com>" format
        if "<" in from_addr and ">" in from_addr:
            from_addr = from_addr.split("<")[1].split(">")[0]

        # Create unsubscribe task
        todoist.create_task(
            content=f"Unsubscribe from {from_addr}",
            labels=["quickwin", "email"]
        )

        # Archive email
        gmail.archive(args.message_id)

        db.log(
            message_id=email["id"],
            thread_id=email["threadId"],
            subject=email["subject"],
            from_addr=email["from"],
            snippet=email["snippet"],
            action="suppress"
        )

        print(json.dumps({"success": True, "action": "suppress", "message_id": args.message_id}))
    finally:
        db.close()


def cmd_stats(args):
    """Show decision statistics."""
    db = DecisionDB()
    stats = db.get_stats()
    db.close()

    print(json.dumps({"success": True, "stats": stats}))


def cmd_labels(args):
    """Get all user labels."""
    gmail = GmailClient()
    labels = gmail.get_labels()
    print(json.dumps({"success": True, "labels": labels}))


def cmd_message_labels(args):
    """Get labels for a specific message."""
    gmail = GmailClient()
    label_ids = gmail.get_message_labels(args.message_id)
    print(json.dumps({"success": True, "labelIds": label_ids}))


def cmd_add_label(args):
    """Add a label to a message."""
    gmail = GmailClient()
    gmail.add_label(args.message_id, args.label_id)
    print(json.dumps({"success": True, "action": "add_label", "label_id": args.label_id}))


def cmd_remove_label(args):
    """Remove a label from a message."""
    gmail = GmailClient()
    gmail.remove_label(args.message_id, args.label_id)
    print(json.dumps({"success": True, "action": "remove_label", "label_id": args.label_id}))


def cmd_setup(args):
    """Run OAuth setup."""
    setup_oauth()


# --- Offline Support Commands ---

CACHE_FILE = Path.home() / ".email-triage-cache.json"


def cmd_cache_save(args):
    """Save emails to cache file for offline use."""
    data = json.loads(args.data)
    with open(CACHE_FILE, "w") as f:
        json.dump(data, f)
    print(json.dumps({"success": True, "cached": len(data.get("emails", []))}))


def cmd_cache_load(args):
    """Load emails from cache file."""
    if not CACHE_FILE.exists():
        print(json.dumps({"success": True, "emails": [], "total": 0, "cached": True}))
        return

    with open(CACHE_FILE, "r") as f:
        data = json.load(f)
    data["cached"] = True
    data["success"] = True
    print(json.dumps(data))


def cmd_queue(args):
    """Queue an action for offline sync."""
    db = DecisionDB()
    try:
        db.queue_action(
            message_id=args.message_id,
            thread_id=args.thread_id or "",
            subject=args.subject or "",
            from_addr=args.from_addr or "",
            snippet=args.snippet or "",
            action=args.action
        )
        print(json.dumps({"success": True, "queued": True, "action": args.action}))
    finally:
        db.close()


def cmd_sync(args):
    """Sync pending actions to Gmail."""
    db = DecisionDB()
    try:
        pending = db.get_pending()
        if not pending:
            print(json.dumps({"success": True, "synced": 0, "pending": 0}))
            return

        # Try to connect to Gmail
        try:
            gmail = GmailClient()
        except Exception as e:
            print(json.dumps({"success": False, "error": "offline", "pending": len(pending)}))
            return

        todoist = None
        synced = 0
        errors = []

        for item in pending:
            try:
                action = item["action"]
                msg_id = item["message_id"]

                if action == "archive":
                    gmail.archive(msg_id)
                elif action == "delete":
                    gmail.delete(msg_id)
                elif action == "task":
                    if todoist is None:
                        todoist = TodoistClient()
                    gmail_link = f"https://mail.google.com/mail/u/0/#inbox/{msg_id}"
                    todoist.create_task(
                        content=f"Handle: {item['subject']}",
                        description=f"From: {item['from_addr']}\n\n{gmail_link}",
                        labels=["email"]
                    )
                    gmail.archive(msg_id)
                elif action == "suppress":
                    if todoist is None:
                        todoist = TodoistClient()
                    from_addr = item["from_addr"]
                    if "<" in from_addr and ">" in from_addr:
                        from_addr = from_addr.split("<")[1].split(">")[0]
                    todoist.create_task(
                        content=f"Unsubscribe from {from_addr}",
                        labels=["quickwin", "email"]
                    )
                    gmail.archive(msg_id)

                # Log the decision
                db.log(
                    message_id=msg_id,
                    thread_id=item["thread_id"],
                    subject=item["subject"],
                    from_addr=item["from_addr"],
                    snippet=item["snippet"],
                    action=action
                )

                # Remove from pending
                db.remove_pending(item["id"])
                synced += 1

            except Exception as e:
                errors.append({"message_id": msg_id, "error": str(e)})

        remaining = db.get_pending()
        print(json.dumps({
            "success": True,
            "synced": synced,
            "pending": len(remaining),
            "errors": errors if errors else None
        }))
    finally:
        db.close()


def cmd_check_online(args):
    """Check if Gmail API is reachable."""
    try:
        gmail = GmailClient()
        # Try a simple API call
        gmail.get_total_inbox_count()
        print(json.dumps({"success": True, "online": True}))
    except Exception as e:
        print(json.dumps({"success": True, "online": False, "error": str(e)}))


def main():
    parser = argparse.ArgumentParser(description="Email Triage Helper")
    subparsers = parser.add_subparsers(dest="command", required=True)

    # fetch
    fetch_parser = subparsers.add_parser("fetch", help="Fetch inbox emails")
    fetch_parser.add_argument("--max", type=int, default=50, help="Max emails to fetch")
    fetch_parser.set_defaults(func=cmd_fetch)

    # archive
    archive_parser = subparsers.add_parser("archive", help="Archive email")
    archive_parser.add_argument("message_id", help="Gmail message ID")
    archive_parser.set_defaults(func=cmd_archive)

    # task
    task_parser = subparsers.add_parser("task", help="Create task and archive")
    task_parser.add_argument("message_id", help="Gmail message ID")
    task_parser.set_defaults(func=cmd_task)

    # delete
    delete_parser = subparsers.add_parser("delete", help="Delete email")
    delete_parser.add_argument("message_id", help="Gmail message ID")
    delete_parser.set_defaults(func=cmd_delete)

    # suppress
    suppress_parser = subparsers.add_parser("suppress", help="Create unsubscribe task and archive")
    suppress_parser.add_argument("message_id", help="Gmail message ID")
    suppress_parser.set_defaults(func=cmd_suppress)

    # unarchive
    unarchive_parser = subparsers.add_parser("unarchive", help="Unarchive email (move back to inbox)")
    unarchive_parser.add_argument("message_id", help="Gmail message ID")
    unarchive_parser.set_defaults(func=cmd_unarchive)

    # undelete
    undelete_parser = subparsers.add_parser("undelete", help="Undelete email (move from trash to inbox)")
    undelete_parser.add_argument("message_id", help="Gmail message ID")
    undelete_parser.set_defaults(func=cmd_undelete)

    # stats
    stats_parser = subparsers.add_parser("stats", help="Show statistics")
    stats_parser.set_defaults(func=cmd_stats)

    # labels
    labels_parser = subparsers.add_parser("labels", help="Get all user labels")
    labels_parser.set_defaults(func=cmd_labels)

    # message-labels
    msg_labels_parser = subparsers.add_parser("message-labels", help="Get labels for a message")
    msg_labels_parser.add_argument("message_id", help="Gmail message ID")
    msg_labels_parser.set_defaults(func=cmd_message_labels)

    # add-label
    add_label_parser = subparsers.add_parser("add-label", help="Add label to message")
    add_label_parser.add_argument("message_id", help="Gmail message ID")
    add_label_parser.add_argument("label_id", help="Label ID")
    add_label_parser.set_defaults(func=cmd_add_label)

    # remove-label
    remove_label_parser = subparsers.add_parser("remove-label", help="Remove label from message")
    remove_label_parser.add_argument("message_id", help="Gmail message ID")
    remove_label_parser.add_argument("label_id", help="Label ID")
    remove_label_parser.set_defaults(func=cmd_remove_label)

    # setup
    setup_parser = subparsers.add_parser("setup", help="Run OAuth setup")
    setup_parser.set_defaults(func=cmd_setup)

    # cache-save
    cache_save_parser = subparsers.add_parser("cache-save", help="Save emails to cache")
    cache_save_parser.add_argument("data", help="JSON data to cache")
    cache_save_parser.set_defaults(func=cmd_cache_save)

    # cache-load
    cache_load_parser = subparsers.add_parser("cache-load", help="Load emails from cache")
    cache_load_parser.set_defaults(func=cmd_cache_load)

    # queue
    queue_parser = subparsers.add_parser("queue", help="Queue offline action")
    queue_parser.add_argument("action", choices=["archive", "task", "delete", "suppress"])
    queue_parser.add_argument("message_id", help="Gmail message ID")
    queue_parser.add_argument("--thread-id", dest="thread_id", default="")
    queue_parser.add_argument("--subject", default="")
    queue_parser.add_argument("--from-addr", dest="from_addr", default="")
    queue_parser.add_argument("--snippet", default="")
    queue_parser.set_defaults(func=cmd_queue)

    # sync
    sync_parser = subparsers.add_parser("sync", help="Sync pending actions")
    sync_parser.set_defaults(func=cmd_sync)

    # check-online
    online_parser = subparsers.add_parser("check-online", help="Check connectivity")
    online_parser.set_defaults(func=cmd_check_online)

    args = parser.parse_args()

    try:
        args.func(args)
    except Exception as e:
        print(json.dumps({"success": False, "error": str(e)}), file=sys.stderr)
        sys.exit(1)


if __name__ == "__main__":
    main()
